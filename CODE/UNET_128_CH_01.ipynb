{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET_128_CH#01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWX55/7iUwH+1/zgsZ7nLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azibfarooq/Lung_cancer_Detection/blob/main/CODE/UNET_128_CH_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wsi_vol, mask_vol = [], []\n",
        "for i, j in zip(glob.glob(wsi_path+'*'), glob.glob(mask_path+'*')):\n",
        "  wsi_vol.append(tiff.imread(i))\n",
        "  mask_vol.append(tiff.imread(j))\n",
        "wsi_vol = np.stack(wsi_vol)\n",
        "mask_vol = np.stack(np.expand_dims(mask_vol, axis=-1))"
      ],
      "metadata": {
        "id": "7L0HzMohB_Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wsi_vol = make_patches(wsi_vol, (128,128,3))\n",
        "mask_vol = make_patches(mask_vol, (128,128,1))\n",
        "print(wsi_vol.shape, mask_vol.shape)"
      ],
      "metadata": {
        "id": "SHVhGwb_CAAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "train_x, train_y = [],[]\n",
        "for i in range(wsi_vol.shape[0]):\n",
        "  img = resize(wsi_vol[i], (128,128,1), mode='constant', preserve_range=True)\n",
        "  train_x.append(img/255.0)\n",
        "  img = resize(mask_vol[i], (128,128,1), mode='constant', preserve_range=True)\n",
        "  train_y.append(img/255.0)\n",
        "train_x = np.stack(train_x)\n",
        "train_y = np.stack(train_y)\n",
        "print(train_x.shape, train_y.shape)"
      ],
      "metadata": {
        "id": "xwWFG6CBCFrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape,X_valid.shape, y_valid.shape)"
      ],
      "metadata": {
        "id": "ezaARw00CLVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # second layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
        "    \"\"\"Function to define the UNET Model\"\"\"\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "    \n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "    \n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "    \n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xTg8xCwICLRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input((im_height, im_width, 1), name='img')\n",
        "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yPvzmHHvCLOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=5, verbose=1, monitor='val_loss'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint('unet128_B5_v1.h5', save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "6DRMs-CNCLK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=callbacks, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "mkTMPobuCLIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation set (this must be equals to the best log_loss)\n",
        "model.evaluate(X_valid, y_valid, verbose=1)"
      ],
      "metadata": {
        "id": "Amx3RpWQCLFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on train, val and test\n",
        "preds_train = model.predict(X_train, verbose=1)\n",
        "preds_val = model.predict(X_valid, verbose=1)"
      ],
      "metadata": {
        "id": "8OBBeEHvFMIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "2lqbDbqmFMtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(train_x, train_y, preds, binary_preds, ix=None):\n",
        "    \"\"\"Function to plot the results\"\"\"\n",
        "    if ix is None:\n",
        "        ix = random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
        "    ax[0].imshow(train_x[ix, ..., 0], cmap='seismic')\n",
        "    if has_mask:\n",
        "        ax[0].contour(train_y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Seismic')\n",
        "\n",
        "    ax[1].imshow(train_y[ix].squeeze())\n",
        "    ax[1].set_title('Cancer')\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[2].contour(train_y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('Cancer Predicted')\n",
        "    \n",
        "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[3].contour(train_y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[3].set_title('Cancer Predicted binary');"
      ],
      "metadata": {
        "id": "xUw24DwGCLDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7C62qLaoCKrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}